**Module 4: Inuit Ublumi Soundscape**

*Macro* 

  This project was really a way to bring everything together and then put it back into the real world completely transformed. Manipulating something in a digital space like in the other modules and having people interact with it on its level is different from trying to bring it to those same people on more or less their terms. There are fewer rules and more interpretations, much like the original piece. It's something you engage with using multiple senses, and have to struggle with to understand and make up your mind. 
  
  It was the simplest project, but the most difficult to explain. I needed to use somebody else's program and allow it to make decisions for me, abstracting the authorship even further. I'm not sure where Karlik, the soundscape software, and I meet, or if any of us have any real ownership of the product aterwards. The software will likely continue to improve, and then the mistakes (if they can be called that) it made with my pictures will make them completely irrelevant. Its lifespan is determined by how much better it *can* be, despite what it is. Very soon it won't have the same meaning because other, and arguably better, interpretations will exist and the evolution will discard old relics like these attempts. But I think that is important in the development of the idea of using AI to categorize history. The contributions and outputs here might turn out to be a piece of the future of tools for the future historian.
  
  In inputting the photos of the model, statue, and poem, I learned more about how the program worked. Certain cchanges in light or distance or background would make huge changes in which sounds were associated with it. Context and subject were equally important, which is sort of how digital history is viewed in the physical world. When removed from its context, and when the design and material was changed, the arch from Palmyra in Trafalgar Square in 2016 became a target for accusations of appropriation and misrepresentation (Kamash). So, bringing it back into the "real world" means having a conscious narrative and a self-reflective attitude toards the respresentation of these objects. Imaginarysoundscape was my way of playing with this idea, and seeing if different narratives could be extracted by something which should be completely objective. Ultimately, I don't thinkit was entirely successful in providing extra insight into how these narratives may arise, but it was a good experiment to see if it was possible. With enough work, it should be possible for others in the future to use this technology and learn from it without having to spend millions of pounds on a mistake.
  
*Micro*
  
  The process notes for this module can be found on the "Process Notes" tab on the main menu, under Module 4. They can also be accessed by following this link: https://github.com/rileyweymann/Notebook/blob/master/process-notes/notesModule4.md
  
  This outlines the basic steps I took in completing this module, as well as some interesting findings I came across while using the imaginarysoundscape software. The nature of this module did not require many steps outside of those mentioned in this file, and the basic use of the software is easily explained on the website. 
